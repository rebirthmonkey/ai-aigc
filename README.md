# AIGC

## 简介

### 定义

训练数据上， LLM 的诞生除了大家熟知的预训练（pre-training）工作，预训练后的指令精调（instruction fine-tuning）工作对于 LLM 能力的激发也至关重要。预训练阶段，使用海量、多样、高质量的文本和代码数据来训练模型的续写能力。在微调阶段，使用多样的人类指令数据来 fine-tune 模型，激发模型响应人类指令的能力。





### 职业发展



## 文本



#### 知识搜索

现存“知识密集性行业”首当其冲的就是“搜索引擎”。某种意义上来讲，“搜索引擎”是人类知识的“前现代存在形式”。每一次搜索请求，其实都是对人类知识的一种索取。但是很遗憾，当前的搜索引擎只是“对知识的索引”，相对于大模型“对知识的压缩”，搜索引擎充满了“低效”和“重复建设”。

从用户体验角度来看，一次搜索、要检索多个页面，然后通过综合多个页面的信息，用户才能做出决策。实际上，这中间的多页面综合、决策，都可以由 LLM 直接做出，大大降低用户体验成本。自从 ChatGPT 出来之后，我使用搜索引擎的比例在逐步下降，身边这样的例子也比比皆是。“搜索引擎被大模型驱动的知识引擎替代”这个趋势我认为是不可逆转的（我暂且使用“知识引擎”这个术语）。

如果大模型下一步能就“事实性信息”和“实时性信息”的训练难题克服的话，我们认为这个替代的拐点就会到来。有些朋友会说，成本障碍会阻挡这一拐点。其实，纵观科技史，成本从来都不是问题，只要某一技术具有十倍、百倍以上的价值提升，那么该技术的成本就会以指数级迅速下降。“知识引擎”相对于“搜索引擎”显然具有十倍、甚至百倍以上的价值提升。

#### 自然语言交互（问答）

问答任务是根据给定的问题，从一个或多个文本片段中提取或生成正确答案的任务。问答系统可以处理各种问题类型，如事实型问题、定义型问题、原因型问题等。问答任务的应用场景包括客户支持、知识库检索、对话系统等。

这里表达的一定程度对通过自然语言进行编程开发的设想，利用自然语言处理技术（NLP）来实现与计算机程序进行交互的接口。通过这种接口，用户可以使用自然语言（如英语、中文等）来表达命令、询问或者描述问题，而不需要具备专业的编程知识。计算机程序会解析这些自然语言输入，将其转换为相应的代码或数据结构，并执行相应的操作。

![image-20230928144102190](figures/image-20230928144102190.png)

聊天机器人表现为同大语言模型的连续对话，同时大语言模型是无状态的，因此需要将历史对话内容累积暂存，后续对话时将相关历史聊天对话同样给到聊天机器人。 倘若聊天对话消息特别多和杂乱时，往往需要通过某种召回策略召回部分关键聊天信息。

![image-20230928144200367](figures/image-20230928144200367.png)

#### 长文总结

文档总结任务是从给定文档中提取关键信息，生成简短且包含主要内容的摘要。总结可以分为抽取式总结和生成式总结。抽取式总结是从原始文档中选择关键句子或短语进行组合；生成式总结则是生成新的句子来表达原始文档的核心内容。文档总结在新闻摘要、会议记录、研究报告等领域有广泛应用。

日常业务应用经常会遇到对一篇文章，一个PDF，一系列对话进行总结概述，当文本内容在大语言模型的上下文限制之内，那么很好解决。但不排除会遇到大量文本的总结诉求，它已经超过上下文限制。那么从工程角度可以通过`MapReduce`的方式进行解决。相关架构如下图：

![image-20230928143943296](figures/image-20230928143943296.png)

#### 数据标注/分类

文本分类是将给定的文本分配到一个或多个预定义类别的任务。这是自然语言处理中常见的监督学习任务。例如，情感分析就是一种文本分类任务，将文本分为正面、负面或中性等类别。其他应用场景还包括垃圾邮件过滤、新闻分类等。

业务中经常会遇到分类，数据标注等任务。例如：

- 根据文档标题和内容 进行行业分类
- 根据支付订单信息 进行行业分类
- 根据文字内容 进行语种分类
- 根据文字内容 进行情感分析

为解决此类问题，核心理念在于是借助 Function 的 Schema 来定义和描述任务。可以通过如下架构流程实现：

1. 定义数据标准或分类 任务 schema 定义（或者直接理解为 Function的参数及其描述）
2. 大语言模型根据提供的Function 预测出应该赋予 Function参数的具体值，这些值即为数据标准或分类的结果

![image-20230928144013954](figures/image-20230928144013954.png)

#### 文本生成

文本生成任务是根据给定的输入（如文本片段、图像、音频等），生成连贯且符合语法规则的自然语言文本。文本生成可以用于各种场景，如机器翻译（将一种语言的文本翻译成另一种语言的文本）、对话系统（生成自然的回复）、创意写作（生成故事、诗歌等）等。



## 代码

#### 代码理解优化

通过将工程源代码以代码分片架构结合向量召回，将提供通用的任意私有代码的代码理解相关能力：

1. 结合代码解答代码相关疑问
2. 对代码提供重构和优化建议
3. 对代码提供注释

![image-20240113111904725](figures/image-20240113111904725.png)



## 图片



## Video



## 生态

### 应用

#### 架构

下图展示了一个理想的 LLM 该有的样子。首先，LLM 应该具备强大的自主学习能力。假设我们把世界上能获得的所有文本或者图片等不同类型的数据喂给它，它应该能够自动从中学习到里面包含的所有知识点，学习过程不需要人的介入，并且能灵活应用所学知识，来解决实际问题。因为数据是海量的，要吸收所有知识，就要非常多的模型参数来存储知识，所以这个模型必然会是一个巨无霸模型。

其次，LLM 应该能解决 NLP 任何子领域的问题，而不仅支持有限领域，甚至它应该可以响应 NLP 之外其它领域的问题，最好是任意领域的问题都能得到很好地回答。

再者，当我们使用 LLM 解决某个具体领域问题的时候，应该用我们人类习惯的表达方式，就是说 LLM 应该理解人类的命令。这体现出让 LLM 适配人，而不是反过来，让人去适配 LLM 模型。人适配 LLM 的典型例子，比如绞尽脑汁去尝试各种不同的 prompt，以试图找到好的提示语，才能很好地解决手头问题。关于这点，上图在人类和 LLM 交互的接口层，举了几个例子，说明什么是好的人使用 LLM 模型的接口形式。

![img](figures/v2-11caaebf977aae428fd8a6302dea2e60_1440w.webp)

训练手段上，成功的 LLM 训练离不开硬件支持、框架支持到训练算法的配合。其中强化学习算法，尤其是主流的基于人类反馈的强化学习（RLHF）有助于对效果进一步的突破，包括缓解“幻觉”、“无中生有”现象、生成更翔实和中立的答案等。



